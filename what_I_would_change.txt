Once I had visualized the data, I saw that data from a lot of zip codes was missing. I realized that during the process of cleaning the 
individual dataframes, I dropped data on a lot of zip codes. For example, if a dataframe had 10 columns but for some of the zip codes, 
there were NAs in some of the columns, I would drop those zip codes so that the cleaned dataframe would only include zip codes for which 
there was data for all 10 of the columns. But when I was merging the dataframes, I would drop 5 of those columns anyway, so there was 
ultimately no point in dropping those zip codes during the individual dataframe cleaning, and if I didn't, I would likely have had more 
zip codes I could have trained the model on, and could have incorporated more zip codes into the visualization. Generally, it seems that if
possible, it is good to wait until the "final cleaning" before dropping critical variables (e.g., zip codes in this case).
